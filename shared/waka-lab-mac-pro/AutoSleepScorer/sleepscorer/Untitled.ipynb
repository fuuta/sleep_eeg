{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylsl import StreamInlet, resolve_stream\n",
    "import numpy as np\n",
    "import scipy.signal as scisig\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from Network import Network\n",
    "from json_encoder import JsonEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import _pickle as cPickle\n",
    "\n",
    "import tensorflow as tf\n",
    "# from keras.backend import tensorflow_backend\n",
    "# config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "# session = tf.Session(config=config)\n",
    "# tensorflow_backend.set_session(session)\n",
    "\n",
    "import keras\n",
    "import keras.callbacks\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "home_path = os.getcwd()\n",
    "\n",
    "config_list = json.load(open(os.path.join(home_path,'config_list.json'),'r'))\n",
    "\n",
    "config = {}\n",
    "config['home_path']= home_path\n",
    "\n",
    "config['label_set_index']= 'easy'\n",
    "config['label_set']= config_list['label_sets'][config['label_set_index']]\n",
    "\n",
    "config['model_type']='CNN'\n",
    "config['time_window'] = 100\n",
    "config['input_len']=5\n",
    "config['output_len']= config['label_set']['num_label']\n",
    "config['input_shape']=(config['time_window'],config['input_len'])\n",
    "\n",
    "config['batch_size']= 128\n",
    "config['loss']= 'categorical_crossentropy'\n",
    "config['n_epochs']= 4\n",
    "config['test_rate']=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config['load']='whole'\n",
    "\n",
    "figsize = (20,8)\n",
    "ymin, ymax = 0, 1\n",
    "max_display_size = 1000\n",
    "num_output= config['output_len']\n",
    "pause_time = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_session = KTF.get_session()\n",
    "with tf.Graph().as_default():\n",
    "    session = tf.Session('')\n",
    "    KTF.set_session(session)\n",
    "    net = Network(config)\n",
    "    net.load('saved_models/20171212-084201')\n",
    "\n",
    "    print(\"looking for an EEG stream...\")\n",
    "    streams = resolve_stream('type', 'EEG')\n",
    "    print(\"detect {} EEG streams!\".format(len(streams)))\n",
    "    inlet = StreamInlet(streams[0],max_buflen=360, max_chunklen=100, recover=True, processing_flags=0)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ion()\n",
    "\n",
    "    ydata = np.zeros((max_display_size,num_output),dtype=np.float32)\n",
    "    ax1=plt.axes()\n",
    "    line = ax1.plot(ydata)\n",
    "    plt.ylim([ymin, ymax])\n",
    "    def update_line(j):\n",
    "        line[j].set_ydata(ydata[:,j])\n",
    "        plt.draw()\n",
    "        return j\n",
    "    \n",
    "    while True:\n",
    "        chunk, timestamps = inlet.pull_chunk()\n",
    "        \n",
    "        ## for test\n",
    "        chunk = np.random.normal(size=(config['time_window'],config['input_len']))\n",
    "        timestamps = 'hogehoge'\n",
    "        \n",
    "        if timestamps:\n",
    "            chunk, timestamps = np.asarray(chunk), np.asarray(timestamps)\n",
    "            print('chunk shape: ',chunk.shape)\n",
    "            chunk = np.reshape(chunk,(1,config['time_window'],config['input_len']),dtype=np.float32)\n",
    "            predict = net.model.predict(chunk,batch_size=1)\n",
    "            print(predict,predict.shape)\n",
    "            predict = np.reshape(predict,(1,num_output),,dtype=np.float32)\n",
    "            plt.ylim([ymin, ymax])\n",
    "            ydata = np.concatenate((ydata,predict),axis=0)[1:]\n",
    "            list(map(update_line,range(len(line))))\n",
    "            plt.pause(pause_time)\n",
    "            \n",
    "#             i += 1\n",
    "#             if i>100: break\n",
    "    \n",
    "    \n",
    "KTF.set_session(old_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_load_and_predict():\n",
    "    old_session = KTF.get_session()\n",
    "    with tf.Graph().as_default():\n",
    "        session = tf.Session('')\n",
    "        KTF.set_session(session)\n",
    "        net = Network(config)\n",
    "        net.load('saved_models/20171212-084201')\n",
    "        print(net.input_shape)\n",
    "        predict = net.model.predict(np.zeros((1,100,5),dtype=np.float32),batch_size=1)\n",
    "        print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_realtime_plot():\n",
    "    from pylsl import StreamInlet, resolve_stream\n",
    "    import numpy as np\n",
    "    import scipy.signal as scisig\n",
    "    import matplotlib.pyplot as plt\n",
    "    import time\n",
    "\n",
    "    figsize = (20,8)\n",
    "    ymin, ymax = 0, 1\n",
    "    max_display_size = 1000\n",
    "    num_output= config['output_len']\n",
    "    pause_time = 0.001\n",
    "\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ion()\n",
    "\n",
    "    ydata = np.zeros((max_display_size,num_output),dtype=np.float32)\n",
    "    ax1=plt.axes()\n",
    "\n",
    "    line = ax1.plot(ydata)\n",
    "    plt.ylim([ymin, ymax])\n",
    "    data = np.random.normal(size=(1,num_output))*0.1\n",
    "\n",
    "    def update_line(j):\n",
    "        line[j].set_ydata(ydata[:,j])\n",
    "        plt.draw()\n",
    "        return j\n",
    "\n",
    "    while True:  \n",
    "        d = np.random.normal(size=(1,num_output))*0.01\n",
    "        data += d\n",
    "        data = data/np.sum(data)\n",
    "        print(data)\n",
    "        plt.ylim([ymin, ymax])\n",
    "        ydata = np.concatenate((ydata,data),axis=0)[1:]\n",
    "        list(map(update_line,range(len(line))))\n",
    "        plt.pause(pause_time)\n",
    "    #     if i>100:\n",
    "    #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_get_stream_and_data():\n",
    "    # first resolve an EEG stream on the lab network\n",
    "    i = 100\n",
    "    print(\"looking for an EEG stream...\")\n",
    "    streams = resolve_stream('type', 'EEG')\n",
    "    print(\"detect {} EEG streams!\".format(len(streams)))\n",
    "    inlet = StreamInlet(streams[0],max_buflen=360, max_chunklen=100, recover=True, processing_flags=0)\n",
    "    while True:\n",
    "        chunk, timestamps = inlet.pull_chunk()\n",
    "        if timestamps:\n",
    "            chunk, timestamps = np.asarray(chunk), np.asarray(timestamps)\n",
    "            print('chunk shape: ',chunk.shape)\n",
    "            i += 1\n",
    "            if i>100: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
